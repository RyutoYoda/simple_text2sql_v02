import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import streamlit as st
import pandas as pd
import duckdb
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
import re
from openai import OpenAI
import faiss
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings('ignore')
from dotenv import load_dotenv

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# æ–°ã—ã„ã‚³ãƒã‚¯ã‚¿ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from src.infrastructure.connectors.factory import ConnectorFactory
    USE_NEW_CONNECTORS = True
except ImportError as e:
    USE_NEW_CONNECTORS = False
    st.error(f"æ–°ã—ã„ã‚³ãƒã‚¯ã‚¿ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“: {e}")

st.set_page_config(page_title="Vizzye", layout="wide", initial_sidebar_state="expanded")

# SQLãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³é–¢æ•°
def is_safe_query(sql: str) -> tuple[bool, str]:
    """
    SELECTæ–‡ã®ã¿ã‚’è¨±å¯ã™ã‚‹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³

    Returns:
        (bool, str): (å®‰å…¨ã‹ã©ã†ã‹, ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸)
    """
    sql_stripped = sql.strip()
    if not sql_stripped:
        return False, "SQLã‚¯ã‚¨ãƒªãŒç©ºã§ã™"

    # å¤§æ–‡å­—ã«å¤‰æ›ã—ã¦ãƒã‚§ãƒƒã‚¯ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚„æ–‡å­—åˆ—ãƒªãƒ†ãƒ©ãƒ«ã‚’è€ƒæ…®ï¼‰
    sql_upper = sql_stripped.upper()

    # WITHå¥ï¼ˆCTEï¼‰ã‚’ã‚µãƒãƒ¼ãƒˆ
    if sql_upper.startswith('WITH'):
        # WITHå¥ã®å ´åˆã€æœ€çµ‚çš„ãªSELECTãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if 'SELECT' not in sql_upper:
            return False, "WITHå¥ã®å¾Œã«SELECTæ–‡ãŒå¿…è¦ã§ã™"
    elif not sql_upper.startswith('SELECT'):
        return False, "SELECTæ–‡ã®ã¿å®Ÿè¡Œå¯èƒ½ã§ã™"

    # å±é™ºãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
    dangerous_keywords = [
        'UPDATE', 'DELETE', 'DROP', 'INSERT', 'CREATE',
        'ALTER', 'TRUNCATE', 'GRANT', 'REVOKE', 'EXEC',
        'EXECUTE', 'MERGE', 'REPLACE'
    ]

    for keyword in dangerous_keywords:
        # å˜èªå¢ƒç•Œã‚’è€ƒæ…®ï¼ˆä¾‹: SELECTå†…ã®"UPDATE"ã¯è¨±å¯ï¼‰
        pattern = r'\b' + keyword + r'\b'
        if re.search(pattern, sql_upper):
            return False, f"å±é™ºãªSQLæ“ä½œãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: {keyword}"

    return True, ""

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'data_sources' not in st.session_state:
    st.session_state.data_sources = {}  # {ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å: {type, df, connector, ...}}
if 'active_source' not in st.session_state:
    st.session_state.active_source = None
if 'messages' not in st.session_state:
    st.session_state.messages = {}  # {ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å: [messages]}
if 'source_counter' not in st.session_state:
    st.session_state.source_counter = 0

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.markdown("### ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ç®¡ç†")

    # æ¥ç¶šæ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ä¸€è¦§
    if st.session_state.data_sources:
        st.markdown("#### ğŸ“‚ æ¥ç¶šæ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹")

        source_names = list(st.session_state.data_sources.keys())

        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚½ãƒ¼ã‚¹é¸æŠ
        active_idx = source_names.index(st.session_state.active_source) if st.session_state.active_source in source_names else 0
        selected_source = st.selectbox(
            "è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹",
            source_names,
            index=active_idx,
            help="åˆ†æã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’é¸æŠ"
        )

        if selected_source != st.session_state.active_source:
            st.session_state.active_source = selected_source
            st.rerun()

        # å‰Šé™¤ãƒœã‚¿ãƒ³
        col1, col2 = st.columns([3, 1])
        with col2:
            if st.button("ğŸ—‘ï¸", key="delete_source", help="é¸æŠä¸­ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’å‰Šé™¤"):
                del st.session_state.data_sources[selected_source]
                if selected_source in st.session_state.messages:
                    del st.session_state.messages[selected_source]
                st.session_state.active_source = list(st.session_state.data_sources.keys())[0] if st.session_state.data_sources else None
                st.rerun()

        st.divider()

    # æ–°è¦ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è¿½åŠ 
    st.markdown("#### â• æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’è¿½åŠ ")

    # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹é¸æŠ
    if USE_NEW_CONNECTORS:
        data_sources = {
            "ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ğŸ“": "local",
            "BigQueryğŸ”": "bigquery",
            "Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆğŸŸ©": "sheets",
            "Snowflakeâ„ï¸": "snowflake",
            "DatabricksğŸ§±": "databricks"
        }
    else:
        data_sources = {
            "ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«": "local",
            "BigQuery": "bigquery",
            "Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ": "sheets"
        }

    source = st.selectbox(
        "ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ç¨®é¡",
        list(data_sources.keys()),
        help="è¿½åŠ ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„"
    )

    st.divider()
    
    # å„ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®æ¥ç¶šè¨­å®š
    if source == "ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ğŸ“":
        source_name = st.text_input("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å", placeholder="ä¾‹: å£²ä¸Šãƒ‡ãƒ¼ã‚¿_2024")
        uploaded_file = st.file_uploader(
            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=["csv", "parquet", "xlsx", "xls"],
            help="CSVã€Parquetã€ã¾ãŸã¯Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
            key="local_file_uploader"
        )
        if uploaded_file and source_name:
            if st.button("ğŸ“¥ è¿½åŠ ", key="add_local"):
                try:
                    if uploaded_file.name.endswith(".csv"):
                        df = pd.read_csv(uploaded_file)
                    elif uploaded_file.name.endswith(".parquet"):
                        df = pd.read_parquet(uploaded_file)
                    elif uploaded_file.name.endswith((".xlsx", ".xls")):
                        df = pd.read_excel(uploaded_file)

                    # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’è¿½åŠ 
                    st.session_state.data_sources[source_name] = {
                        "type": "local",
                        "df": df,
                        "connector": None,
                        "file_name": uploaded_file.name
                    }
                    st.session_state.active_source = source_name
                    st.session_state.messages[source_name] = []
                    st.success(f"âœ… {source_name}ã‚’è¿½åŠ ã—ã¾ã—ãŸï¼")
                    st.rerun()
                except Exception as e:
                    st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    elif source == "BigQueryğŸ”":
        with st.expander("æ¥ç¶šè¨­å®š", expanded=True):
            source_name = st.text_input("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å", placeholder="ä¾‹: ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆDB", key="bq_name")
            sa_file = st.file_uploader(
                "ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆJSON",
                type="json",
                key="bq_sa",
                help="BigQueryã®ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆJSONãƒ•ã‚¡ã‚¤ãƒ«"
            )

            # ä¸€æ™‚çš„ãªæ¥ç¶šçŠ¶æ…‹
            if 'temp_bq_client' not in st.session_state:
                st.session_state.temp_bq_client = None

            if sa_file and source_name:
                if st.button("ğŸ”— BigQueryã«æ¥ç¶š", key="bq_connect"):
                    try:
                        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
                        with open("temp_bq.json", "wb") as f:
                            f.write(sa_file.getbuffer())
                        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "temp_bq.json"

                        from google.cloud import bigquery
                        client = bigquery.Client()
                        st.session_state.temp_bq_client = client
                        st.success("âœ… æ¥ç¶šæˆåŠŸï¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")
                        st.rerun()
                    except Exception as e:
                        st.error(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")

        # æ¥ç¶šå¾Œã®ãƒ‡ãƒ¼ã‚¿é¸æŠ
        if st.session_state.temp_bq_client:
            try:
                client = st.session_state.temp_bq_client
                datasets = list(client.list_datasets())
                dataset_names = [d.dataset_id for d in datasets]

                selected_dataset = st.selectbox("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ", dataset_names, key="bq_dataset")

                if selected_dataset:
                    tables = list(client.list_tables(selected_dataset))
                    table_names = [t.table_id for t in tables]
                    selected_table = st.selectbox("ãƒ†ãƒ¼ãƒ–ãƒ«", table_names, key="bq_table")

                    if selected_table:
                        if st.button("ğŸ“¥ è¿½åŠ ", key="add_bq"):
                            with st.spinner("ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­..."):
                                full_table_id = f"{client.project}.{selected_dataset}.{selected_table}"
                                query = f"SELECT * FROM `{full_table_id}` LIMIT 1000"
                                df = client.query(query).to_dataframe()

                                source_name = st.session_state.get("bq_name", f"BigQuery_{st.session_state.source_counter}")
                                st.session_state.source_counter += 1

                                # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’è¿½åŠ 
                                st.session_state.data_sources[source_name] = {
                                    "type": "bigquery",
                                    "df": df,
                                    "connector": client,
                                    "dataset": selected_dataset,
                                    "table": selected_table
                                }
                                st.session_state.active_source = source_name
                                st.session_state.messages[source_name] = []
                                st.session_state.temp_bq_client = None
                                st.success(f"âœ… {source_name}ã‚’è¿½åŠ ã—ã¾ã—ãŸï¼")
                                st.rerun()
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
    
    elif source == "Snowflakeâ„ï¸" and USE_NEW_CONNECTORS:
        with st.expander("æ¥ç¶šè¨­å®š", expanded=True):
            source_name = st.text_input("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å", placeholder="ä¾‹: Snowflakeæœ¬ç•ªDB", key="sf_name")
            account = st.text_input("ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ", placeholder="xxx.snowflakecomputing.com", key="sf_account")
            username = st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼å", key="sf_username")
            warehouse = st.text_input("ã‚¦ã‚§ã‚¢ãƒã‚¦ã‚¹", key="sf_warehouse")

            private_key_file = st.file_uploader(
                "ç§˜å¯†éµãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆPEMï¼‰",
                type=["pem", "key"],
                help="Programmatic Access Tokenç”¨ã®ç§˜å¯†éµ",
                key="sf_key"
            )
            passphrase = st.text_input("ãƒ‘ã‚¹ãƒ•ãƒ¬ãƒ¼ã‚ºï¼ˆä»»æ„ï¼‰", type="password", key="sf_pass")

            # ä¸€æ™‚çš„ãªæ¥ç¶šçŠ¶æ…‹
            if 'temp_sf_connector' not in st.session_state:
                st.session_state.temp_sf_connector = None

            if all([account, username, warehouse, private_key_file, source_name]):
                if st.button("ğŸ”— Snowflakeã«æ¥ç¶š", key="sf_connect"):
                    try:
                        private_key_content = private_key_file.read().decode('utf-8')
                        connector = ConnectorFactory.create_connector("snowflake")
                        credentials = {
                            "account": account,
                            "user": username,
                            "private_key": private_key_content,
                            "private_key_passphrase": passphrase if passphrase else None,
                            "warehouse": warehouse
                        }

                        with st.spinner("æ¥ç¶šä¸­..."):
                            connector.connect(credentials)
                            st.session_state.temp_sf_connector = connector
                            st.success("âœ… æ¥ç¶šæˆåŠŸï¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")
                            st.rerun()
                    except Exception as e:
                        st.error(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")

        # æ¥ç¶šå¾Œã®ãƒ‡ãƒ¼ã‚¿é¸æŠ
        if st.session_state.temp_sf_connector:
            try:
                connector = st.session_state.temp_sf_connector
                databases = connector.list_datasets()
                selected_db = st.selectbox("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹", databases, key="sf_db")

                if selected_db:
                    if hasattr(connector, 'list_schemas'):
                        schemas = connector.list_schemas(selected_db)
                        selected_schema = st.selectbox("ã‚¹ã‚­ãƒ¼ãƒ", schemas, key="sf_schema")

                        if selected_schema:
                            tables = connector.list_tables(selected_db, selected_schema)
                            selected_table = st.selectbox("ãƒ†ãƒ¼ãƒ–ãƒ«", tables, key="sf_table")

                            if selected_table:
                                if st.button("ğŸ“¥ è¿½åŠ ", key="add_sf"):
                                    with st.spinner("ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­..."):
                                        df = connector.get_sample_data(selected_db, selected_table, selected_schema)

                                        source_name = st.session_state.get("sf_name", f"Snowflake_{st.session_state.source_counter}")
                                        st.session_state.source_counter += 1

                                        # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’è¿½åŠ 
                                        st.session_state.data_sources[source_name] = {
                                            "type": "snowflake",
                                            "df": df,
                                            "connector": connector,
                                            "database": selected_db,
                                            "schema": selected_schema,
                                            "table": selected_table
                                        }
                                        st.session_state.active_source = source_name
                                        st.session_state.messages[source_name] = []
                                        st.session_state.temp_sf_connector = None
                                        st.success(f"âœ… {source_name}ã‚’è¿½åŠ ã—ã¾ã—ãŸï¼")
                                        st.rerun()
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
    
    elif source == "DatabricksğŸ§±" and USE_NEW_CONNECTORS:
        with st.expander("æ¥ç¶šè¨­å®š", expanded=True):
            source_name = st.text_input("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å", placeholder="ä¾‹: Databricksåˆ†æç’°å¢ƒ", key="db_name")
            server_hostname = st.text_input("ã‚µãƒ¼ãƒãƒ¼ãƒ›ã‚¹ãƒˆ", placeholder="xxx.cloud.databricks.com", key="db_host")
            http_path = st.text_input("HTTPãƒ‘ã‚¹", placeholder="/sql/1.0/endpoints/xxx", key="db_path")
            access_token = st.text_input("Access Token", type="password", help="Personal Access Token", key="db_token")
            catalog = st.text_input("ã‚«ã‚¿ãƒ­ã‚°ï¼ˆä»»æ„ï¼‰", key="db_catalog")

            # ä¸€æ™‚çš„ãªæ¥ç¶šçŠ¶æ…‹
            if 'temp_db_connector' not in st.session_state:
                st.session_state.temp_db_connector = None

            if all([server_hostname, http_path, access_token, source_name]):
                if st.button("ğŸ”— Databricksã«æ¥ç¶š", key="db_connect"):
                    try:
                        connector = ConnectorFactory.create_connector("databricks")
                        credentials = {
                            "server_hostname": server_hostname,
                            "http_path": http_path,
                            "access_token": access_token,
                            "catalog": catalog if catalog else None
                        }

                        with st.spinner("æ¥ç¶šä¸­..."):
                            connector.connect(credentials)
                            st.session_state.temp_db_connector = connector
                            st.success("âœ… æ¥ç¶šæˆåŠŸï¼ã‚«ã‚¿ãƒ­ã‚°ã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")
                            st.rerun()
                    except Exception as e:
                        st.error(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")

        # æ¥ç¶šå¾Œã®ãƒ‡ãƒ¼ã‚¿é¸æŠ
        if st.session_state.temp_db_connector:
            try:
                connector = st.session_state.temp_db_connector

                catalogs = connector.list_datasets()
                selected_catalog = st.selectbox("ã‚«ã‚¿ãƒ­ã‚°", catalogs, key="db_cat_select")

                if selected_catalog:
                    if type(connector).__name__ in ['SnowflakeConnector', 'DatabricksConnector']:
                        schemas = connector.list_schemas(selected_catalog)
                        selected_schema = st.selectbox("ã‚¹ã‚­ãƒ¼ãƒ", schemas, key="db_schema_select")

                        if selected_schema:
                            tables = connector.list_tables(selected_catalog, selected_schema)
                            selected_table = st.selectbox("ãƒ†ãƒ¼ãƒ–ãƒ«", tables, key="db_table_select")

                            if selected_table:
                                if st.button("ğŸ“¥ è¿½åŠ ", key="add_db"):
                                    with st.spinner("ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­..."):
                                        df = connector.get_sample_data(selected_catalog, selected_table, schema=selected_schema)

                                        source_name = st.session_state.get("db_name", f"Databricks_{st.session_state.source_counter}")
                                        st.session_state.source_counter += 1

                                        # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’è¿½åŠ 
                                        st.session_state.data_sources[source_name] = {
                                            "type": "databricks",
                                            "df": df,
                                            "connector": connector,
                                            "catalog": selected_catalog,
                                            "schema": selected_schema,
                                            "table": selected_table
                                        }
                                        st.session_state.active_source = source_name
                                        st.session_state.messages[source_name] = []
                                        st.session_state.temp_db_connector = None
                                        st.success(f"âœ… {source_name}ã‚’è¿½åŠ ã—ã¾ã—ãŸï¼")
                                        st.rerun()
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
    
    elif source == "Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆğŸŸ©" and USE_NEW_CONNECTORS:
        with st.expander("æ¥ç¶šè¨­å®š", expanded=True):
            source_name = st.text_input("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å", placeholder="ä¾‹: å£²ä¸Šç®¡ç†ã‚·ãƒ¼ãƒˆ", key="gs_name")
            sa_file = st.file_uploader(
                "ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆJSON",
                type="json",
                key="gs_sa",
                help="Google SheetsAPIã‚¢ã‚¯ã‚»ã‚¹ç”¨ã®ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆJSONãƒ•ã‚¡ã‚¤ãƒ«"
            )
            sheet_url = st.text_input("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆURL", placeholder="https://docs.google.com/spreadsheets/d/...", key="gs_url")

            # ä¸€æ™‚çš„ãªæ¥ç¶šçŠ¶æ…‹
            if 'temp_gs_connector' not in st.session_state:
                st.session_state.temp_gs_connector = None

            if all([sa_file, sheet_url, source_name]):
                if st.button("ğŸ”— Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«æ¥ç¶š", key="gs_connect"):
                    try:
                        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
                        with open("temp_gs.json", "wb") as f:
                            f.write(sa_file.getbuffer())

                        connector = ConnectorFactory.create_connector("google_sheets")
                        credentials = {
                            "service_account_file": "temp_gs.json",
                            "sheet_url": sheet_url
                        }

                        with st.spinner("æ¥ç¶šä¸­..."):
                            connector.connect(credentials)
                            st.session_state.temp_gs_connector = connector
                            st.success("âœ… æ¥ç¶šæˆåŠŸï¼ã‚·ãƒ¼ãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„")
                            st.rerun()
                    except Exception as e:
                        st.error(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")

        # æ¥ç¶šå¾Œã®ãƒ‡ãƒ¼ã‚¿é¸æŠ
        if st.session_state.temp_gs_connector:
            try:
                connector = st.session_state.temp_gs_connector
                sheets = connector.list_tables("")  # Google Sheetsã§ã¯datasetãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¸è¦
                selected_sheet = st.selectbox("ã‚·ãƒ¼ãƒˆ", sheets, key="gs_sheet_select")

                if selected_sheet:
                    if st.button("ğŸ“¥ è¿½åŠ ", key="add_gs"):
                        with st.spinner("ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­..."):
                            df = connector.get_sample_data("", selected_sheet)

                            source_name = st.session_state.get("gs_name", f"GoogleSheets_{st.session_state.source_counter}")
                            st.session_state.source_counter += 1

                            # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’è¿½åŠ 
                            st.session_state.data_sources[source_name] = {
                                "type": "google_sheets",
                                "df": df,
                                "connector": connector,
                                "sheet_name": selected_sheet
                            }
                            st.session_state.active_source = source_name
                            st.session_state.messages[source_name] = []
                            st.session_state.temp_gs_connector = None
                            st.success(f"âœ… {source_name}ã‚’è¿½åŠ ã—ã¾ã—ãŸï¼")
                            st.rerun()
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
st.title("ğŸ§ Vizzy - Adhoc Analytics Assistant")

# ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
if st.session_state.active_source and st.session_state.active_source in st.session_state.data_sources:
    active_data = st.session_state.data_sources[st.session_state.active_source]
    df = active_data['df']

    # æ—¥ä»˜ã‚«ãƒ©ãƒ ã®è‡ªå‹•å¤‰æ›
    for col in df.columns:
        if "date" in col.lower() or "time" in col.lower():
            try:
                df[col] = pd.to_datetime(df[col])
            except:
                pass

    # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®ç¨®é¡ã‚’åˆ¤å®š
    connector = None
    duck_conn = None

    if active_data['connector']:
        connector = active_data['connector']
        dialect = connector.get_dialect() if hasattr(connector, 'get_dialect') else 'duckdb'
    else:
        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯DuckDBã‚’ä½¿ç”¨
        dialect = 'duckdb'

    # DuckDBãŒå¿…è¦ãªå ´åˆã¯å¸¸ã«åˆæœŸåŒ–
    if dialect == 'duckdb':
        duck_conn = duckdb.connect()
        duck_conn.register("data", df)

    # ã‚«ãƒ©ãƒ åˆ†å‰²: å·¦ã«ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€å³ã«ãƒãƒ£ãƒƒãƒˆ
    col_left, col_right = st.columns([1, 2])

    with col_left:
        st.subheader("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.write(f"**{st.session_state.active_source}**")
        st.write(f"ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(df):,}è¡Œ Ã— {len(df.columns)}åˆ—")
        st.dataframe(df.head(100), height=600)

    with col_right:
        st.subheader("ğŸ’¬ ãƒ‡ãƒ¼ã‚¿åˆ†æãƒãƒ£ãƒƒãƒˆ")

        # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’åˆæœŸåŒ–ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
        if st.session_state.active_source not in st.session_state.messages:
            st.session_state.messages[st.session_state.active_source] = []

        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è¡¨ç¤º
        for idx, message in enumerate(st.session_state.messages[st.session_state.active_source]):
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
                # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ãƒ‡ãƒ¼ã‚¿ã¨ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤º
                if message["role"] == "assistant" and "data" in message:
                    if "sql" in message:
                        with st.expander("ç”Ÿæˆã•ã‚ŒãŸSQL"):
                            st.code(message["sql"], language="sql")
                    if "dataframe" in message:
                        st.dataframe(message["dataframe"])
                    if "figure" in message:
                        st.plotly_chart(message["figure"], width="stretch")
                    if "summary" in message:
                        with st.expander("åˆ†æè¦ç´„", expanded=True):
                            st.markdown(message["summary"])

                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                    if "dataframe" in message and "timestamp" in message:
                        col1, col2 = st.columns(2)
                        with col1:
                            # HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
                            html_report = f"""
                            <html>
                            <head>
                                <title>Vizzyåˆ†æãƒ¬ãƒãƒ¼ãƒˆ - {message['timestamp'].strftime('%Y/%m/%d %H:%M')}</title>
                                <style>
                                    body {{ font-family: Arial, sans-serif; margin: 40px; }}
                                    h1, h2 {{ color: #333; }}
                                    .query {{ background-color: #f0f0f0; padding: 10px; border-radius: 5px; }}
                                    .sql {{ background-color: #e8e8e8; padding: 10px; border-radius: 5px; font-family: monospace; white-space: pre-wrap; }}
                                    .summary {{ background-color: #f9f9f9; padding: 15px; border-radius: 5px; margin: 20px 0; }}
                                    table {{ border-collapse: collapse; width: 100%; }}
                                    th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                                    th {{ background-color: #4CAF50; color: white; }}
                                </style>
                            </head>
                            <body>
                                <h1>Vizzy åˆ†æãƒ¬ãƒãƒ¼ãƒˆ</h1>
                                <p><strong>ä½œæˆæ—¥æ™‚:</strong> {message['timestamp'].strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}</p>

                                <h2>è³ªå•</h2>
                                <div class="query">{message.get('question', '')}</div>

                                <h2>å®Ÿè¡Œã—ãŸSQL</h2>
                                <div class="sql">{message.get('sql', '')}</div>

                                <h2>åˆ†æè¦ç´„</h2>
                                <div class="summary">{message.get('summary', 'è¦ç´„ãªã—')}</div>

                                <h2>ã‚°ãƒ©ãƒ•</h2>
                                {message.get('figure', '').to_html() if 'figure' in message else '<p>ã‚°ãƒ©ãƒ•ãªã—</p>'}

                                <h2>ãƒ‡ãƒ¼ã‚¿ï¼ˆä¸Šä½20è¡Œï¼‰</h2>
                                {message['dataframe'].head(20).to_html()}
                            </body>
                            </html>
                            """

                            st.download_button(
                                label="ğŸ“„ HTMLãƒ¬ãƒãƒ¼ãƒˆ",
                                data=html_report,
                                file_name=f"vizzy_report_{message['timestamp'].strftime('%Y%m%d_%H%M%S')}.html",
                                mime="text/html",
                                key=f"html_{idx}"
                            )

                        with col2:
                            csv = message['dataframe'].to_csv(index=False)
                            st.download_button(
                                label="ğŸ“Š CSVãƒ‡ãƒ¼ã‚¿",
                                data=csv,
                                file_name=f"vizzy_data_{message['timestamp'].strftime('%Y%m%d_%H%M%S')}.csv",
                                mime="text/csv",
                                key=f"csv_{idx}"
                            )

        # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›
        if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹: æœˆåˆ¥ã®å£²ä¸Šæ¨ç§»ã‚’è¦‹ã›ã¦ï¼‰"):
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
            with st.chat_message("user"):
                st.markdown(prompt)

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ 
            st.session_state.messages[st.session_state.active_source].append({"role": "user", "content": prompt})

            # APIã‚­ãƒ¼å–å¾—
            openai_api_key = os.getenv("OPENAI_API_KEY")
            if not openai_api_key:
                st.error("OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã«OPENAI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
                st.stop()

            client = OpenAI(api_key=openai_api_key)

            # ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±å–å¾—
            schema = {}
            for col in df.columns:
                dtype = str(df[col].dtype)
                schema[col] = dtype

            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
            sample_data = df.head(3).to_string()

            # SQLç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ¥ã«æœ€é©åŒ–ï¼‰
            if dialect == 'snowflake':
                # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ã‚’å–å¾—
                if 'database' in active_data and 'schema' in active_data and 'table' in active_data:
                    table_ref = f"{active_data['database']}.{active_data['schema']}.{active_data['table']}"
                else:
                    table_ref = "data"

                sql_generation_prompt = f"""
ä»¥ä¸‹ã®ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ã‚’åŸºã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹Snowflake SQLã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ãƒ†ãƒ¼ãƒ–ãƒ«å: {table_ref}
ã‚«ãƒ©ãƒ æƒ…å ±: {schema}

ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿:
{sample_data}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}

é‡è¦ãªæŒ‡ç¤º:
- Snowflakeã®æ§‹æ–‡ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨
- **ã‚«ãƒ©ãƒ åãŒå°æ–‡å­—ã®å ´åˆã¯å¿…ãšãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã§å›²ã‚€ã“ã¨** (ä¾‹: "name", "user_id")
- å¤§æ–‡å­—ã®ã‚«ãƒ©ãƒ åã¯ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆä¸è¦ (ä¾‹: NAME, USER_ID)
- ã‚¨ã‚¤ãƒªã‚¢ã‚¹ï¼ˆASå¥ï¼‰ã‚‚å°æ–‡å­—ã®å ´åˆã¯ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã§å›²ã‚€ã“ã¨
- æ—¥ä»˜é–¢æ•°: DATE_TRUNC(), DATEADD(), DATEDIFF()ãªã©
- æ–‡å­—åˆ—é–¢æ•°: CONCAT(), SPLIT_PART(), REGEXP_SUBSTR()ãªã©
- ã‚°ãƒ©ãƒ•ã‚’è¦æ±‚ã•ã‚ŒãŸå ´åˆã¯ã€é©åˆ‡ãªGROUP BYã¨ORDER BYã‚’å«ã‚ã‚‹
- SQLã‚¯ã‚¨ãƒªã®ã¿ã‚’è¿”ã™ï¼ˆèª¬æ˜ã¯ä¸è¦ï¼‰
"""
            elif dialect == 'bigquery':
                # BigQueryã®å ´åˆã‚‚ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ã‚’å–å¾—
                if 'dataset' in active_data and 'table' in active_data:
                    # BigQueryã®connectorã‹ã‚‰project_idã‚’å–å¾—
                    if connector and hasattr(connector, 'connection'):
                        project_id = connector.connection.project
                        table_ref = f"`{project_id}.{active_data['dataset']}.{active_data['table']}`"
                    else:
                        table_ref = f"{active_data['dataset']}.{active_data['table']}"
                else:
                    table_ref = "data"

                sql_generation_prompt = f"""
ä»¥ä¸‹ã®ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ã‚’åŸºã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹BigQuery SQLã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ãƒ†ãƒ¼ãƒ–ãƒ«å: {table_ref}
ã‚«ãƒ©ãƒ æƒ…å ±: {schema}

ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿:
{sample_data}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}

é‡è¦ãªæŒ‡ç¤º:
- BigQueryã®æ¨™æº–SQLæ§‹æ–‡ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨
- æ—¥ä»˜é–¢æ•°: DATE_TRUNC(), DATE_ADD(), DATE_DIFF()ãªã©
- ARRAYã€STRUCTãªã©ã®è¤‡é›‘ãªå‹ã‚‚è€ƒæ…®
- ã‚°ãƒ©ãƒ•ã‚’è¦æ±‚ã•ã‚ŒãŸå ´åˆã¯ã€é©åˆ‡ãªGROUP BYã¨ORDER BYã‚’å«ã‚ã‚‹
- SQLã‚¯ã‚¨ãƒªã®ã¿ã‚’è¿”ã™ï¼ˆèª¬æ˜ã¯ä¸è¦ï¼‰
"""
            elif dialect == 'databricks':
                # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ã‚’å–å¾—
                if 'catalog' in active_data and 'schema' in active_data and 'table' in active_data:
                    table_ref = f"{active_data['catalog']}.{active_data['schema']}.{active_data['table']}"
                else:
                    table_ref = "data"

                sql_generation_prompt = f"""
ä»¥ä¸‹ã®ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ã‚’åŸºã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹Databricks SQLã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ãƒ†ãƒ¼ãƒ–ãƒ«å: {table_ref}
ã‚«ãƒ©ãƒ æƒ…å ±: {schema}

ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿:
{sample_data}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}

é‡è¦ãªæŒ‡ç¤º:
- Databricksã®æ§‹æ–‡ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ï¼ˆSpark SQLãƒ™ãƒ¼ã‚¹ï¼‰
- æ—¥ä»˜é–¢æ•°: date_trunc(), date_add(), datediff()ãªã©
- ã‚«ã‚¿ãƒ­ã‚°.ã‚¹ã‚­ãƒ¼ãƒ.ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã®å®Œå…¨ä¿®é£¾åã‚’ä½¿ç”¨
- ã‚°ãƒ©ãƒ•ã‚’è¦æ±‚ã•ã‚ŒãŸå ´åˆã¯ã€é©åˆ‡ãªGROUP BYã¨ORDER BYã‚’å«ã‚ã‚‹
- SQLã‚¯ã‚¨ãƒªã®ã¿ã‚’è¿”ã™ï¼ˆèª¬æ˜ã¯ä¸è¦ï¼‰
"""
            else:  # DuckDB (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)
                sql_generation_prompt = f"""
ä»¥ä¸‹ã®ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ã‚’åŸºã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹DuckDB SQLã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ãƒ†ãƒ¼ãƒ•ãƒ«å: data
ã‚«ãƒ©ãƒ æƒ…å ±: {schema}

ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿:
{sample_data}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}

é‡è¦ãªæŒ‡ç¤º:
- DuckDBã®æ§‹æ–‡ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨
- æ—¥ä»˜å‹ã®ã‚«ãƒ©ãƒ ã¯CAST(column_name AS DATE)ã‚’ä½¿ç”¨
- ã‚°ãƒ©ãƒ•ã‚’è¦æ±‚ã•ã‚ŒãŸå ´åˆã¯ã€é©åˆ‡ãªGROUP BYã¨ORDER BYã‚’å«ã‚ã‚‹
- SQLã‚¯ã‚¨ãƒªã®ã¿ã‚’è¿”ã™ï¼ˆèª¬æ˜ã¯ä¸è¦ï¼‰
"""

            try:
                with st.chat_message("assistant"):
                    with st.spinner("SQLç”Ÿæˆä¸­..."):
                        response = client.chat.completions.create(
                            model="gpt-5-nano",
                            messages=[
                                {"role": "system", "content": "ã‚ãªãŸã¯SQLç”Ÿæˆã®å°‚é–€å®¶ã§ã™ã€‚"},
                                {"role": "user", "content": sql_generation_prompt}
                            ]
                        )

                    sql_query = response.choices[0].message.content.strip()
                    sql_query = sql_query.replace("```sql", "").replace("```", "").strip()

                    with st.expander("ç”Ÿæˆã•ã‚ŒãŸSQL", expanded=False):
                        st.code(sql_query, language="sql")

                    # SQLãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
                    is_safe, error_message = is_safe_query(sql_query)
                    if not is_safe:
                        st.error(f"ğŸš« ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¨ãƒ©ãƒ¼: {error_message}")
                        st.warning("ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯SELECTæ–‡ã®ã¿å®Ÿè¡Œå¯èƒ½ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›´ãƒ»å‰Šé™¤ã‚’è¡Œã†SQLæ“ä½œã¯è¨±å¯ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                        st.session_state.messages[st.session_state.active_source].append({
                            "role": "assistant",
                            "content": f"ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ç”Ÿæˆã•ã‚ŒãŸSQLãŒå®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n\nã‚¨ãƒ©ãƒ¼: {error_message}\n\nã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯SELECTæ–‡ã®ã¿å®Ÿè¡Œå¯èƒ½ã§ã™ã€‚",
                            "sql": sql_query,
                            "error": error_message
                        })
                        st.stop()

                    # ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
                    try:
                        with st.spinner("ã‚¯ã‚¨ãƒªå®Ÿè¡Œä¸­..."):
                            if dialect in ['snowflake', 'bigquery', 'databricks'] and connector and hasattr(connector, 'execute_query'):
                                result_df = connector.execute_query(sql_query)
                            elif duck_conn is not None:
                                result_df = duck_conn.execute(sql_query).fetchdf()
                            else:
                                raise RuntimeError(f"ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹'{active_data['type']}'ã§ã®ã‚¯ã‚¨ãƒªå®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸã€‚DuckDBæ¥ç¶šãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

                        st.dataframe(result_df)

                        # åˆ†æè¦ç´„ã®ç”Ÿæˆ
                        with st.spinner("åˆ†æçµæœã‚’è¦ç´„ä¸­..."):
                            summary_prompt = f"""
ä»¥ä¸‹ã®åˆ†æçµæœã‚’è¦ç´„ã—ã¦ãã ã•ã„ï¼š

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}
å®Ÿè¡Œã—ãŸSQL: {sql_query}

çµæœãƒ‡ãƒ¼ã‚¿ï¼ˆä¸Šä½10è¡Œï¼‰:
{result_df.head(10).to_string()}

ä»¥ä¸‹ã®å½¢å¼ã§è¦ç´„ã—ã¦ãã ã•ã„ï¼š
1. ä¸»ãªç™ºè¦‹ï¼ˆ2-3å€‹ã®é‡è¦ãªãƒã‚¤ãƒ³ãƒˆï¼‰
2. ãƒ‡ãƒ¼ã‚¿ã®å‚¾å‘ã‚„ç‰¹å¾´
3. ãƒ“ã‚¸ãƒã‚¹ä¸Šã®ç¤ºå”†ï¼ˆã‚ã‚Œã°ï¼‰

ç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ã„æ—¥æœ¬èªã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
"""
                            try:
                                summary_response = client.chat.completions.create(
                                    model="gpt-5-nano",
                                    messages=[
                                        {"role": "system", "content": "ã‚ãªãŸã¯ãƒ‡ãƒ¼ã‚¿åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚"},
                                        {"role": "user", "content": summary_prompt}
                                    ]
                                )
                                analysis_summary = summary_response.choices[0].message.content.strip()

                                with st.expander("åˆ†æè¦ç´„", expanded=True):
                                    st.markdown(analysis_summary)
                            except Exception as e:
                                st.warning(f"è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
                                analysis_summary = "è¦ç´„ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"

                        # ã‚°ãƒ©ãƒ•ç”Ÿæˆ
                        fig = None
                        if len(result_df.columns) >= 2:
                            query_lower = prompt.lower()
                            colors = ['#4361ee', '#3f37c9', '#7209b7', '#b5179e', '#f72585',
                                     '#4cc9f0', '#4895ef', '#480ca8', '#560bad', '#6a4c93']

                            if any(word in prompt for word in ["å††", "å‰²åˆ", "æ¯”ç‡", "æ§‹æˆ", "å†…è¨³"]) or "pie" in query_lower:
                                fig = px.pie(result_df, names=result_df.columns[0], values=result_df.columns[1],
                                           title=prompt, color_discrete_sequence=colors)
                                fig.update_layout(plot_bgcolor='white', paper_bgcolor='white', font=dict(color='#333333'))
                                st.plotly_chart(fig, width="stretch")

                            elif any(word in prompt for word in ["æ™‚ç³»åˆ—", "æ¨ç§»", "å¤‰åŒ–", "æŠ˜ã‚Œç·š"]) or any(word in query_lower for word in ["trend", "line"]):
                                fig = px.line(result_df, x=result_df.columns[0], y=result_df.columns[1],
                                            title=prompt, color_discrete_sequence=['#4361ee'])
                                fig.update_layout(plot_bgcolor='white', paper_bgcolor='white', font=dict(color='#333333'),
                                                xaxis=dict(gridcolor='#e0e0e0'), yaxis=dict(gridcolor='#e0e0e0'))
                                st.plotly_chart(fig, width="stretch")

                            elif any(word in prompt for word in ["é–¢ä¿‚", "ç›¸é–¢", "æ•£å¸ƒ"]) or any(word in query_lower for word in ["scatter", "correlation"]):
                                fig = px.scatter(result_df, x=result_df.columns[0], y=result_df.columns[1],
                                               title=prompt, color_discrete_sequence=['#4361ee'])
                                fig.update_layout(plot_bgcolor='white', paper_bgcolor='white', font=dict(color='#333333'),
                                                xaxis=dict(gridcolor='#e0e0e0'), yaxis=dict(gridcolor='#e0e0e0'))
                                st.plotly_chart(fig, width="stretch")

                            else:
                                if len(result_df) > 0:
                                    result_df_sorted = result_df.sort_values(by=result_df.columns[1], ascending=False)
                                else:
                                    result_df_sorted = result_df
                                fig = px.bar(result_df_sorted, x=result_df_sorted.columns[0], y=result_df_sorted.columns[1],
                                           title=prompt, color_discrete_sequence=['#4361ee'])
                                fig.update_layout(plot_bgcolor='white', paper_bgcolor='white', font=dict(color='#333333'),
                                                xaxis=dict(gridcolor='#e0e0e0'), yaxis=dict(gridcolor='#e0e0e0'))
                                st.plotly_chart(fig, width="stretch")

                        # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ 
                        assistant_message = {
                            "role": "assistant",
                            "content": f"åˆ†æçµæœã‚’è¡¨ç¤ºã—ã¾ã—ãŸã€‚",
                            "data": True,
                            "sql": sql_query,
                            "dataframe": result_df,
                            "summary": analysis_summary,
                            "question": prompt,
                            "timestamp": pd.Timestamp.now()
                        }
                        if fig:
                            assistant_message["figure"] = fig
                        st.session_state.messages[st.session_state.active_source].append(assistant_message)

                        # æ–°ã—ãç”Ÿæˆã•ã‚ŒãŸçµæœã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                        col1, col2 = st.columns(2)
                        with col1:
                            # HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
                            html_report = f"""
                            <html>
                            <head>
                                <title>Vizzyåˆ†æãƒ¬ãƒãƒ¼ãƒˆ - {assistant_message['timestamp'].strftime('%Y/%m/%d %H:%M')}</title>
                                <style>
                                    body {{ font-family: Arial, sans-serif; margin: 40px; }}
                                    h1, h2 {{ color: #333; }}
                                    .query {{ background-color: #f0f0f0; padding: 10px; border-radius: 5px; }}
                                    .sql {{ background-color: #e8e8e8; padding: 10px; border-radius: 5px; font-family: monospace; white-space: pre-wrap; }}
                                    .summary {{ background-color: #f9f9f9; padding: 15px; border-radius: 5px; margin: 20px 0; }}
                                    table {{ border-collapse: collapse; width: 100%; }}
                                    th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                                    th {{ background-color: #4CAF50; color: white; }}
                                </style>
                            </head>
                            <body>
                                <h1>Vizzy åˆ†æãƒ¬ãƒãƒ¼ãƒˆ</h1>
                                <p><strong>ä½œæˆæ—¥æ™‚:</strong> {assistant_message['timestamp'].strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}</p>

                                <h2>è³ªå•</h2>
                                <div class="query">{prompt}</div>

                                <h2>å®Ÿè¡Œã—ãŸSQL</h2>
                                <div class="sql">{sql_query}</div>

                                <h2>åˆ†æè¦ç´„</h2>
                                <div class="summary">{analysis_summary}</div>

                                <h2>ã‚°ãƒ©ãƒ•</h2>
                                {fig.to_html() if fig else '<p>ã‚°ãƒ©ãƒ•ãªã—</p>'}

                                <h2>ãƒ‡ãƒ¼ã‚¿ï¼ˆä¸Šä½20è¡Œï¼‰</h2>
                                {result_df.head(20).to_html()}
                            </body>
                            </html>
                            """

                            st.download_button(
                                label="ğŸ“„ HTMLãƒ¬ãƒãƒ¼ãƒˆ",
                                data=html_report,
                                file_name=f"vizzy_report_{assistant_message['timestamp'].strftime('%Y%m%d_%H%M%S')}.html",
                                mime="text/html",
                                key="html_new"
                            )

                        with col2:
                            csv = result_df.to_csv(index=False)
                            st.download_button(
                                label="ğŸ“Š CSVãƒ‡ãƒ¼ã‚¿",
                                data=csv,
                                file_name=f"vizzy_data_{assistant_message['timestamp'].strftime('%Y%m%d_%H%M%S')}.csv",
                                mime="text/csv",
                                key="csv_new"
                            )

                    except Exception as e:
                        st.error(f"SQLã‚¨ãƒ©ãƒ¼: {e}")

            except Exception as e:
                st.error(f"AIç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")

else:
    # ãƒ‡ãƒ¼ã‚¿æœªãƒ­ãƒ¼ãƒ‰æ™‚ã®æ¡ˆå†…
    st.info("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„")

    with st.expander("ä½¿ã„æ–¹", expanded=True):
        st.markdown("""
### ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

#### ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®è¿½åŠ 
1. **ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ç¨®é¡ã‚’é¸æŠ**: ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œæ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’è¿½åŠ ã€ã‹ã‚‰é¸æŠ
2. **ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åã‚’å…¥åŠ›**: ã‚ã‹ã‚Šã‚„ã™ã„åå‰ã‚’ã¤ã‘ã‚‹ï¼ˆä¾‹: "å£²ä¸Šãƒ‡ãƒ¼ã‚¿2024"ï¼‰
3. **æ¥ç¶šè¨­å®š**: å¿…è¦ãªèªè¨¼æƒ…å ±ã‚’å…¥åŠ›ã—ã¦æ¥ç¶š
4. **ãƒ†ãƒ¼ãƒ–ãƒ«é¸æŠ**: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ/ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠ
5. **è¿½åŠ **: ã€ŒğŸ“¥ è¿½åŠ ã€ãƒœã‚¿ãƒ³ã§ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’è¿½åŠ 

#### åˆ†æã®å®Ÿè¡Œ
1. **ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ‡ã‚Šæ›¿ãˆ**: ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã‹ã‚‰é¸æŠ
2. **ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼**: å·¦å´ã§ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª
3. **ãƒãƒ£ãƒƒãƒˆã§è³ªå•**: å³å´ã®ãƒãƒ£ãƒƒãƒˆæ¬„ã«è‡ªç„¶è¨€èªã§å…¥åŠ›
4. **çµæœç¢ºèª**: SQLã€ã‚°ãƒ©ãƒ•ã€åˆ†æè¦ç´„ãŒè‡ªå‹•ç”Ÿæˆ
5. **ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜**: HTMLãƒ¬ãƒãƒ¼ãƒˆã‚„CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

### ğŸ“Š å¯¾å¿œãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹

- **ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«**: CSV, Parquet
- **BigQuery**: Google Cloud BigQuery
- **Snowflake**: Programmatic Access Tokenèªè¨¼
- **Databricks**: Personal Access Tokenèªè¨¼
- **Google Sheets**: ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼

### âœ¨ è¤‡æ•°ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æ©Ÿèƒ½

- è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’åŒæ™‚ã«æ¥ç¶šå¯èƒ½
- ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ç°¡å˜ã«åˆ‡ã‚Šæ›¿ãˆ
- å„ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã”ã¨ã«ç‹¬ç«‹ã—ãŸãƒãƒ£ãƒƒãƒˆå±¥æ­´
- ä¸è¦ãªãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã¯ğŸ—‘ï¸ãƒœã‚¿ãƒ³ã§å‰Šé™¤

### ğŸ’¡ è³ªå•ä¾‹

- ã€Œæœˆåˆ¥ã®å£²ä¸Šæ¨ç§»ã‚’è¦‹ã›ã¦ã€
- ã€Œã‚«ãƒ†ã‚´ãƒªåˆ¥ã®å£²ä¸Šã‚’æ£’ã‚°ãƒ©ãƒ•ã§è¡¨ç¤ºã€
- ã€Œä¸Šä½10å•†å“ã®å£²ä¸Šå‰²åˆã‚’å††ã‚°ãƒ©ãƒ•ã§ã€
- ã€Œæ˜¨å¹´åŒæœˆæ¯”ã®æˆé•·ç‡ã‚’è¨ˆç®—ã—ã¦ã€
        """)
