import streamlit as st
import pandas as pd
import sqlite3
import plotly.express as px
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

# ---------------------
# ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ï¼ˆåˆå›ã ã‘ï¼‰
# ---------------------
@st.cache_resource
def load_model():
    tokenizer = AutoTokenizer.from_pretrained("cyberagent/calm3-22b-chat")
    model = AutoModelForCausalLM.from_pretrained(
        "cyberagent/calm3-22b-chat",
        device_map="auto",
        torch_dtype=torch.float16  # ã‚‚ã—ãã¯ "auto"
    )
    return model, tokenizer

st.title("ğŸ’¬ Text2SQL ãƒãƒ£ãƒƒãƒˆ Ã— CALM3")
st.markdown("è‡ªç„¶è¨€èªã§è³ªå•ã™ã‚‹ã¨ã€SQLã‚’ç”Ÿæˆã—ã¦ã‚°ãƒ©ãƒ•åŒ–ã—ã¾ã™ã€‚")

model, tokenizer = load_model()

# ---------------------
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# ---------------------
uploaded_file = st.file_uploader("ğŸ“„ CSVã¾ãŸã¯Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv", "parquet"])

if uploaded_file:
    if uploaded_file.name.endswith(".csv"):
        df = pd.read_csv(uploaded_file)
    else:
        df = pd.read_parquet(uploaded_file)
    st.success("âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸï¼")
    st.dataframe(df.head())

    conn = sqlite3.connect(":memory:")
    df.to_sql("data", conn, index=False, if_exists="replace")

    # ---------------------
    # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›
    # ---------------------
    user_input = st.chat_input("è‡ªç„¶è¨€èªã§ãƒ‡ãƒ¼ã‚¿ã«è³ªå•ã—ã¦ã¿ã‚ˆã†ï¼ˆä¾‹ï¼šæœˆåˆ¥ã®å£²ä¸Šåˆè¨ˆï¼‰")

    if user_input:
        with st.chat_message("user"):
            st.markdown(user_input)

        with st.chat_message("assistant"):
            with st.spinner("SQLã‚’ç”Ÿæˆä¸­..."):

                # ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±
                table_info = "\n".join([f"{col}: {str(dtype)}" for col, dtype in zip(df.columns, df.dtypes)])

                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
                prompt = f"""ã‚ãªãŸã¯ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã«å¯¾ã—ã¦ã€è³ªå•ã«ç­”ãˆã‚‹SQLiteã‚¯ã‚¨ãƒªã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±:
{table_info}

è³ªå•:
{user_input}

SQL:"""

                # å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³ä½œæˆ
                messages = [
                    {"role": "system", "content": "ã‚ãªãŸã¯SQLã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"},
                    {"role": "user", "content": prompt}
                ]
                input_ids = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors="pt").to(model.device)

                # ãƒ¢ãƒ‡ãƒ«æ¨è«–
                output_ids = model.generate(input_ids, max_new_tokens=256, temperature=0.3)
                response = tokenizer.decode(output_ids[0], skip_special_tokens=True)

                # SQLæŠ½å‡º
                sql_start = response.find("SELECT")
                sql_query = response[sql_start:] if sql_start >= 0 else response

                st.markdown(f"ğŸ§  **ç”Ÿæˆã•ã‚ŒãŸSQLã‚¯ã‚¨ãƒª**:\n```sql\n{sql_query}\n```")

                # SQLå®Ÿè¡Œ
                try:
                    result_df = pd.read_sql_query(sql_query, conn)
                    st.dataframe(result_df)

                    # ã‚°ãƒ©ãƒ•è¡¨ç¤ºï¼ˆ2åˆ—ï¼‰
                    if result_df.shape[1] == 2:
                        fig = px.bar(result_df, x=result_df.columns[0], y=result_df.columns[1])
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.info("2åˆ—ã®çµæœã®ã¿ã‚°ãƒ©ãƒ•åŒ–ã•ã‚Œã¾ã™ã€‚")
                except Exception as e:
                    st.error(f"âŒ SQLå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
else:
    st.info("ã¾ãšã¯CSVã¾ãŸã¯Parquetã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
