import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import streamlit as st
import pandas as pd
import duckdb
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
import re
from openai import OpenAI
import faiss
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings('ignore')

# æ–°ã—ã„ã‚³ãƒã‚¯ã‚¿ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from src.infrastructure.connectors.factory import ConnectorFactory
    USE_NEW_CONNECTORS = True
except ImportError as e:
    USE_NEW_CONNECTORS = False
    st.error(f"æ–°ã—ã„ã‚³ãƒã‚¯ã‚¿ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“: {e}")

st.set_page_config(page_title="Vizzye", layout="wide", initial_sidebar_state="expanded")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'df' not in st.session_state:
    st.session_state.df = None
if 'connected' not in st.session_state:
    st.session_state.connected = False
if 'connector' not in st.session_state:
    st.session_state.connector = None

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.markdown("### ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è¨­å®š")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹é¸æŠ
    if USE_NEW_CONNECTORS:
        data_sources = {
            "ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ğŸ“": "local",
            "BigQueryğŸ”": "bigquery", 
            "Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆğŸŸ©": "sheets",
            "Snowflakeâ„ï¸": "snowflake",
            "DatabricksğŸ§±": "databricks"
        }
    else:
        data_sources = {
            "ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«": "local",
            "BigQuery": "bigquery",
            "Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ": "sheets"
        }
    
    source = st.selectbox(
        "ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’é¸æŠ",
        list(data_sources.keys()),
        help="åˆ©ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„"
    )
    
    st.divider()
    
    # å„ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®æ¥ç¶šè¨­å®š
    if source == "ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ğŸ“":
        uploaded_file = st.file_uploader(
            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=["csv", "parquet"],
            help="CSVã¾ãŸã¯Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
        )
        if uploaded_file:
            try:
                if uploaded_file.name.endswith(".csv"):
                    st.session_state.df = pd.read_csv(uploaded_file)
                else:
                    st.session_state.df = pd.read_parquet(uploaded_file)
                st.success("âœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸï¼")
                st.session_state.connected = True
            except Exception as e:
                st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    elif source == "BigQueryğŸ”":
        with st.expander("æ¥ç¶šè¨­å®š", expanded=True):
            sa_file = st.file_uploader(
                "ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆJSON",
                type="json",
                key="bq_sa",
                help="BigQueryã®ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆJSONãƒ•ã‚¡ã‚¤ãƒ«"
            )
            
            if sa_file:
                if st.button("ğŸ”— BigQueryã«æ¥ç¶š", key="bq_connect"):
                    try:
                        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
                        with open("temp_bq.json", "wb") as f:
                            f.write(sa_file.getbuffer())
                        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "temp_bq.json"
                        
                        from google.cloud import bigquery
                        client = bigquery.Client()
                        st.session_state.bq_client = client
                        st.session_state.connected = True
                        st.success("âœ… æ¥ç¶šæˆåŠŸï¼")
                    except Exception as e:
                        st.error(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        
        # æ¥ç¶šå¾Œã®ãƒ‡ãƒ¼ã‚¿é¸æŠ
        if st.session_state.connected and hasattr(st.session_state, 'bq_client'):
            try:
                client = st.session_state.bq_client
                datasets = list(client.list_datasets())
                dataset_names = [d.dataset_id for d in datasets]
                
                selected_dataset = st.selectbox("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ", dataset_names)
                
                if selected_dataset:
                    tables = list(client.list_tables(selected_dataset))
                    table_names = [t.table_id for t in tables]
                    selected_table = st.selectbox("ãƒ†ãƒ¼ãƒ–ãƒ«", table_names)
                    
                    if selected_table:
                        if st.button("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿å–å¾—", key="bq_fetch"):
                            with st.spinner("ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­..."):
                                full_table_id = f"{client.project}.{selected_dataset}.{selected_table}"
                                query = f"SELECT * FROM `{full_table_id}` LIMIT 1000"
                                st.session_state.df = client.query(query).to_dataframe()
                                st.success(f"âœ… {len(st.session_state.df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—")
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
    
    elif source == "Snowflakeâ„ï¸" and USE_NEW_CONNECTORS:
        with st.expander("æ¥ç¶šè¨­å®š", expanded=True):
            account = st.text_input("ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ", placeholder="xxx.snowflakecomputing.com")
            username = st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼å")
            warehouse = st.text_input("ã‚¦ã‚§ã‚¢ãƒã‚¦ã‚¹")
            
            private_key_file = st.file_uploader(
                "ç§˜å¯†éµãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆPEMï¼‰",
                type=["pem", "key"],
                help="Programmatic Access Tokenç”¨ã®ç§˜å¯†éµ"
            )
            passphrase = st.text_input("ãƒ‘ã‚¹ãƒ•ãƒ¬ãƒ¼ã‚ºï¼ˆä»»æ„ï¼‰", type="password")
            
            if st.button("ğŸ”— Snowflakeã«æ¥ç¶š", key="sf_connect"):
                if all([account, username, warehouse, private_key_file]):
                    try:
                        private_key_content = private_key_file.read().decode('utf-8')
                        connector = ConnectorFactory.create_connector("snowflake")
                        credentials = {
                            "account": account,
                            "user": username,
                            "private_key": private_key_content,
                            "private_key_passphrase": passphrase if passphrase else None,
                            "warehouse": warehouse
                        }
                        
                        with st.spinner("æ¥ç¶šä¸­..."):
                            connector.connect(credentials)
                            st.session_state.connector = connector
                            st.session_state.connected = True
                            st.success("âœ… æ¥ç¶šæˆåŠŸï¼")
                    except Exception as e:
                        st.error(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
                else:
                    st.warning("ã™ã¹ã¦ã®å¿…é ˆé …ç›®ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        
        # æ¥ç¶šå¾Œã®ãƒ‡ãƒ¼ã‚¿é¸æŠ
        if st.session_state.connected and st.session_state.connector:
            try:
                connector = st.session_state.connector
                databases = connector.list_datasets()
                selected_db = st.selectbox("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹", databases)
                
                if selected_db:
                    # Snowflakeã®å ´åˆã¯ã‚¹ã‚­ãƒ¼ãƒé¸æŠã‚‚è¿½åŠ 
                    if hasattr(connector, 'list_schemas'):
                        schemas = connector.list_schemas(selected_db)
                        selected_schema = st.selectbox("ã‚¹ã‚­ãƒ¼ãƒ", schemas)
                        
                        if selected_schema:
                            tables = connector.list_tables(selected_db, selected_schema)
                            selected_table = st.selectbox("ãƒ†ãƒ¼ãƒ–ãƒ«", tables)
                            
                            if selected_table:
                                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜ï¼ˆSQLç”Ÿæˆæ™‚ã«ä½¿ç”¨ï¼‰
                                st.session_state.selected_db = selected_db
                                st.session_state.selected_schema = selected_schema
                                st.session_state.selected_table = selected_table
                                
                                if st.button("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿å–å¾—", key="sf_fetch"):
                                    with st.spinner("ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­..."):
                                        st.session_state.df = connector.get_sample_data(selected_db, selected_table, selected_schema)
                                        st.success(f"âœ… {len(st.session_state.df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—")
                    else:
                        tables = connector.list_tables(selected_db)
                        selected_table = st.selectbox("ãƒ†ãƒ¼ãƒ–ãƒ«", tables)
                        
                        if selected_table:
                            if st.button("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿å–å¾—", key="sf_fetch"):
                                with st.spinner("ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­..."):
                                    st.session_state.df = connector.get_sample_data(selected_db, selected_table)
                                    st.success(f"âœ… {len(st.session_state.df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—")
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
    
    elif source == "DatabricksğŸ§±" and USE_NEW_CONNECTORS:
        with st.expander("æ¥ç¶šè¨­å®š", expanded=True):
            server_hostname = st.text_input("ã‚µãƒ¼ãƒãƒ¼ãƒ›ã‚¹ãƒˆ", placeholder="xxx.cloud.databricks.com")
            http_path = st.text_input("HTTPãƒ‘ã‚¹", placeholder="/sql/1.0/endpoints/xxx")
            access_token = st.text_input("Access Token", type="password", help="Personal Access Token")
            catalog = st.text_input("ã‚«ã‚¿ãƒ­ã‚°ï¼ˆä»»æ„ï¼‰")
            
            if st.button("ğŸ”— Databricksã«æ¥ç¶š", key="db_connect"):
                if all([server_hostname, http_path, access_token]):
                    try:
                        connector = ConnectorFactory.create_connector("databricks")
                        credentials = {
                            "server_hostname": server_hostname,
                            "http_path": http_path,
                            "access_token": access_token,
                            "catalog": catalog if catalog else None
                        }
                        
                        with st.spinner("æ¥ç¶šä¸­..."):
                            connector.connect(credentials)
                            st.session_state.connector = connector
                            st.session_state.connected = True
                            st.success("âœ… æ¥ç¶šæˆåŠŸï¼")
                    except Exception as e:
                        st.error(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
                else:
                    st.warning("ã™ã¹ã¦ã®å¿…é ˆé …ç›®ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        
        # æ¥ç¶šå¾Œã®ãƒ‡ãƒ¼ã‚¿é¸æŠ
        if st.session_state.connected and st.session_state.connector:
            try:
                connector = st.session_state.connector
                print(f"DEBUG - Connector class name: {type(connector).__name__}")
                
                catalogs = connector.list_datasets()
                selected_catalog = st.selectbox("ã‚«ã‚¿ãƒ­ã‚°", catalogs)
                
                if selected_catalog:
                    # Snowflakeã¨Databricksã®å ´åˆã¯ã‚¹ã‚­ãƒ¼ãƒé¸æŠã‚‚è¿½åŠ 
                    if type(connector).__name__ in ['SnowflakeConnector', 'DatabricksConnector']:
                        print(f"DEBUG - Schema selection UI should be shown")
                        schemas = connector.list_schemas(selected_catalog)
                        selected_schema = st.selectbox("ã‚¹ã‚­ãƒ¼ãƒ", schemas)
                        
                        if selected_schema:
                            tables = connector.list_tables(selected_catalog, selected_schema)
                            selected_table = st.selectbox("ãƒ†ãƒ¼ãƒ–ãƒ«", tables)
                            
                            if selected_table:
                                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                                st.session_state.selected_catalog = selected_catalog
                                st.session_state.selected_schema = selected_schema
                                st.session_state.selected_table = selected_table
                                
                                if st.button("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿å–å¾—", key="db_fetch"):
                                    with st.spinner("ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­..."):
                                        st.session_state.df = connector.get_sample_data(selected_catalog, selected_table, schema=selected_schema)
                                        st.success(f"âœ… {len(st.session_state.df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—")
                    else:
                        print(f"DEBUG - Schema selection UI NOT shown for {type(connector).__name__}")
                        tables = connector.list_tables(selected_catalog)
                        selected_table = st.selectbox("ãƒ†ãƒ¼ãƒ–ãƒ«", tables)
                        
                        if selected_table:
                            if st.button("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿å–å¾—", key="db_fetch"):
                                with st.spinner("ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­..."):
                                    st.session_state.df = connector.get_sample_data(selected_catalog, selected_table)
                                    st.success(f"âœ… {len(st.session_state.df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—")
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
    
    elif source == "Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆğŸŸ©" and USE_NEW_CONNECTORS:
        with st.expander("æ¥ç¶šè¨­å®š", expanded=True):
            sa_file = st.file_uploader(
                "ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆJSON",
                type="json",
                key="gs_sa",
                help="Google SheetsAPIã‚¢ã‚¯ã‚»ã‚¹ç”¨ã®ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆJSONãƒ•ã‚¡ã‚¤ãƒ«"
            )
            sheet_url = st.text_input("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆURL", placeholder="https://docs.google.com/spreadsheets/d/...")
            
            if st.button("ğŸ”— Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«æ¥ç¶š", key="gs_connect"):
                if all([sa_file, sheet_url]):
                    try:
                        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
                        with open("temp_gs.json", "wb") as f:
                            f.write(sa_file.getbuffer())
                        
                        connector = ConnectorFactory.create_connector("google_sheets")
                        credentials = {
                            "service_account_file": "temp_gs.json",
                            "sheet_url": sheet_url
                        }
                        
                        with st.spinner("æ¥ç¶šä¸­..."):
                            connector.connect(credentials)
                            st.session_state.connector = connector
                            st.session_state.connected = True
                            st.success("âœ… æ¥ç¶šæˆåŠŸï¼")
                    except Exception as e:
                        st.error(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
                else:
                    st.warning("ã™ã¹ã¦ã®å¿…é ˆé …ç›®ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        
        # æ¥ç¶šå¾Œã®ãƒ‡ãƒ¼ã‚¿é¸æŠ
        if st.session_state.connected and st.session_state.connector:
            try:
                connector = st.session_state.connector
                sheets = connector.list_tables("")  # Google Sheetsã§ã¯datasetãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¸è¦
                selected_sheet = st.selectbox("ã‚·ãƒ¼ãƒˆ", sheets)
                
                if selected_sheet:
                    if st.button("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿å–å¾—", key="gs_fetch"):
                        with st.spinner("ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­..."):
                            st.session_state.df = connector.get_sample_data("", selected_sheet)
                            st.success(f"âœ… {len(st.session_state.df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—")
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
st.title("ğŸ§ Vizzy - Adhoc Analytics Assistant")

# ãƒ‡ãƒ¼ã‚¿ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
if st.session_state.df is not None:
    df = st.session_state.df
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    with st.expander("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", expanded=True):
        st.write(f"ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(df):,}è¡Œ Ã— {len(df.columns)}åˆ—")
        st.dataframe(df.head(100))
    
    # æ—¥ä»˜ã‚«ãƒ©ãƒ ã®è‡ªå‹•å¤‰æ›
    for col in df.columns:
        if "date" in col.lower() or "time" in col.lower():
            try:
                df[col] = pd.to_datetime(df[col])
            except:
                pass
    
    # Text2SQLæ©Ÿèƒ½
    st.header("è‡ªç„¶è¨€èªã§ãƒ‡ãƒ¼ã‚¿ã‚’æ¢ç´¢")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®ç¨®é¡ã‚’åˆ¤å®š
    if hasattr(st.session_state, 'connector') and st.session_state.connector:
        connector = st.session_state.connector
        dialect = connector.get_dialect() if hasattr(connector, 'get_dialect') else 'duckdb'
    else:
        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯DuckDBã‚’ä½¿ç”¨
        dialect = 'duckdb'
        duck_conn = duckdb.connect()
        duck_conn.register("data", df)
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        query_input = st.text_area(
            "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            placeholder="ä¾‹: å£²ä¸Šã®æœˆåˆ¥æ¨ç§»ã‚’è¦‹ã›ã¦ã€ä¸Šä½10å•†å“ã®å£²ä¸Šã‚’æ£’ã‚°ãƒ©ãƒ•ã§è¡¨ç¤ºã—ã¦",
            height=100
        )
    
    with col2:
        st.write("")
        st.write("")
        analyze_button = st.button("ğŸ” åˆ†æå®Ÿè¡Œ", type="primary", use_container_width=True)
    
    if analyze_button and query_input:
        openai_api_key = st.secrets.get("OPENAI_API_KEY")
        if not openai_api_key:
            openai_api_key = st.text_input("OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›", type="password")
        
        if openai_api_key:
            client = OpenAI(api_key=openai_api_key)
            
            # ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±å–å¾—
            schema = {}
            for col in df.columns:
                dtype = str(df[col].dtype)
                schema[col] = dtype
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
            sample_data = df.head(3).to_string()
            
            # SQLç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ¥ã«æœ€é©åŒ–ï¼‰
            if dialect == 'snowflake':
                # Snowflakeç”¨ã®ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±å–å¾—
                if hasattr(st.session_state, 'selected_db') and hasattr(st.session_state, 'selected_schema') and hasattr(st.session_state, 'selected_table'):
                    table_ref = f"{st.session_state.selected_db}.{st.session_state.selected_schema}.{st.session_state.selected_table}"
                else:
                    table_ref = "data"
                    
                prompt = f"""
ä»¥ä¸‹ã®ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ã‚’åŸºã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹Snowflake SQLã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ãƒ†ãƒ¼ãƒ–ãƒ«å: {table_ref}
ã‚«ãƒ©ãƒ æƒ…å ±: {schema}

ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿:
{sample_data}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {query_input}

é‡è¦ãªæŒ‡ç¤º:
- Snowflakeã®æ§‹æ–‡ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨
- æ—¥ä»˜é–¢æ•°: DATE_TRUNC(), DATEADD(), DATEDIFF()ãªã©
- æ–‡å­—åˆ—é–¢æ•°: CONCAT(), SPLIT_PART(), REGEXP_SUBSTR()ãªã©
- ã‚°ãƒ©ãƒ•ã‚’è¦æ±‚ã•ã‚ŒãŸå ´åˆã¯ã€é©åˆ‡ãªGROUP BYã¨ORDER BYã‚’å«ã‚ã‚‹
- SQLã‚¯ã‚¨ãƒªã®ã¿ã‚’è¿”ã™ï¼ˆèª¬æ˜ã¯ä¸è¦ï¼‰
"""
            elif dialect == 'bigquery':
                prompt = f"""
ä»¥ä¸‹ã®ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ã‚’åŸºã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹BigQuery SQLã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ãƒ†ãƒ¼ãƒ–ãƒ«å: data
ã‚«ãƒ©ãƒ æƒ…å ±: {schema}

ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿:
{sample_data}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {query_input}

é‡è¦ãªæŒ‡ç¤º:
- BigQueryã®æ¨™æº–SQLæ§‹æ–‡ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨
- æ—¥ä»˜é–¢æ•°: DATE_TRUNC(), DATE_ADD(), DATE_DIFF()ãªã©
- ARRAYã€STRUCTãªã©ã®è¤‡é›‘ãªå‹ã‚‚è€ƒæ…®
- ã‚°ãƒ©ãƒ•ã‚’è¦æ±‚ã•ã‚ŒãŸå ´åˆã¯ã€é©åˆ‡ãªGROUP BYã¨ORDER BYã‚’å«ã‚ã‚‹
- SQLã‚¯ã‚¨ãƒªã®ã¿ã‚’è¿”ã™ï¼ˆèª¬æ˜ã¯ä¸è¦ï¼‰
"""
            elif dialect == 'databricks':
                # Databricksç”¨ã®ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±å–å¾—
                if hasattr(st.session_state, 'selected_catalog') and hasattr(st.session_state, 'selected_schema') and hasattr(st.session_state, 'selected_table'):
                    table_ref = f"{st.session_state.selected_catalog}.{st.session_state.selected_schema}.{st.session_state.selected_table}"
                else:
                    table_ref = "data"
                    
                prompt = f"""
ä»¥ä¸‹ã®ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ã‚’åŸºã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹Databricks SQLã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ãƒ†ãƒ¼ãƒ–ãƒ«å: {table_ref}
ã‚«ãƒ©ãƒ æƒ…å ±: {schema}

ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿:
{sample_data}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {query_input}

é‡è¦ãªæŒ‡ç¤º:
- Databricksã®æ§‹æ–‡ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ï¼ˆSpark SQLãƒ™ãƒ¼ã‚¹ï¼‰
- æ—¥ä»˜é–¢æ•°: date_trunc(), date_add(), datediff()ãªã©
- ã‚«ã‚¿ãƒ­ã‚°.ã‚¹ã‚­ãƒ¼ãƒ.ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã®å®Œå…¨ä¿®é£¾åã‚’ä½¿ç”¨
- ã‚°ãƒ©ãƒ•ã‚’è¦æ±‚ã•ã‚ŒãŸå ´åˆã¯ã€é©åˆ‡ãªGROUP BYã¨ORDER BYã‚’å«ã‚ã‚‹
- SQLã‚¯ã‚¨ãƒªã®ã¿ã‚’è¿”ã™ï¼ˆèª¬æ˜ã¯ä¸è¦ï¼‰
"""
            else:  # DuckDB (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)
                prompt = f"""
ä»¥ä¸‹ã®ãƒ†ãƒ¼ãƒ–ãƒ«æƒ…å ±ã‚’åŸºã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã‚‹DuckDB SQLã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ãƒ†ãƒ¼ãƒ•ãƒ«å: data
ã‚«ãƒ©ãƒ æƒ…å ±: {schema}

ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿:
{sample_data}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {query_input}

é‡è¦ãªæŒ‡ç¤º:
- DuckDBã®æ§‹æ–‡ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨
- æ—¥ä»˜å‹ã®ã‚«ãƒ©ãƒ ã¯CAST(column_name AS DATE)ã‚’ä½¿ç”¨
- ã‚°ãƒ©ãƒ•ã‚’è¦æ±‚ã•ã‚ŒãŸå ´åˆã¯ã€é©åˆ‡ãªGROUP BYã¨ORDER BYã‚’å«ã‚ã‚‹
- SQLã‚¯ã‚¨ãƒªã®ã¿ã‚’è¿”ã™ï¼ˆèª¬æ˜ã¯ä¸è¦ï¼‰
"""
            
            try:
                with st.spinner("SQLç”Ÿæˆä¸­..."):
                    response = client.chat.completions.create(
                        model="gpt-3.5-turbo",
                        messages=[
                            {"role": "system", "content": "ã‚ãªãŸã¯SQLç”Ÿæˆã®å°‚é–€å®¶ã§ã™ã€‚"},
                            {"role": "user", "content": prompt}
                        ]
                    )
                
                sql_query = response.choices[0].message.content.strip()
                sql_query = sql_query.replace("```sql", "").replace("```", "").strip()
                
                st.code(sql_query, language="sql")
                
                # ã‚¯ã‚¨ãƒªå®Ÿè¡Œï¼ˆãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹åˆ¥ï¼‰
                try:
                    if dialect in ['snowflake', 'bigquery', 'databricks'] and hasattr(connector, 'execute_query'):
                        # å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å ´åˆã¯ç›´æ¥å®Ÿè¡Œ
                        result_df = connector.execute_query(sql_query)
                    else:
                        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯DuckDBã§å®Ÿè¡Œ
                        result_df = duck_conn.execute(sql_query).fetchdf()
                    
                    # çµæœè¡¨ç¤º
                    st.subheader("ğŸ“Š çµæœ")
                    st.dataframe(result_df)
                    
                    # ã‚°ãƒ©ãƒ•ç”Ÿæˆã®åˆ¤å®šã¨ä½œæˆ
                    if len(result_df.columns) >= 2:
                        # ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒ—ã‚’æ¨å®š
                        query_lower = query_input.lower()
                        
                        # å††ã‚°ãƒ©ãƒ•: å††ã€å‰²åˆã€æ¯”ç‡ã€æ§‹æˆ
                        if any(word in query_input for word in ["å††", "å‰²åˆ", "æ¯”ç‡", "æ§‹æˆ", "å†…è¨³"]) or "pie" in query_lower:
                            fig = px.pie(result_df, names=result_df.columns[0], values=result_df.columns[1])
                            st.plotly_chart(fig, use_container_width=True)
                            
                        # æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•: æ™‚ç³»åˆ—ã€æ¨ç§»ã€å¤‰åŒ–ã€ãƒˆãƒ¬ãƒ³ãƒ‰
                        elif any(word in query_input for word in ["æ™‚ç³»åˆ—", "æ¨ç§»", "å¤‰åŒ–", "æŠ˜ã‚Œç·š"]) or any(word in query_lower for word in ["trend", "line"]):
                            fig = px.line(result_df, x=result_df.columns[0], y=result_df.columns[1])
                            st.plotly_chart(fig, use_container_width=True)
                            
                        # æ•£å¸ƒå›³: é–¢ä¿‚ã€ç›¸é–¢ã€æ•£å¸ƒ
                        elif any(word in query_input for word in ["é–¢ä¿‚", "ç›¸é–¢", "æ•£å¸ƒ"]) or any(word in query_lower for word in ["scatter", "correlation"]):
                            if len(result_df.columns) >= 2:
                                fig = px.scatter(result_df, x=result_df.columns[0], y=result_df.columns[1])
                                st.plotly_chart(fig, use_container_width=True)
                            
                        # æ£’ã‚°ãƒ©ãƒ•ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰: æ£’ã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€ä¸Šä½ã€ä¸‹ä½
                        else:
                            # ãƒ‡ãƒ¼ã‚¿ã‚’é™é †ã«ã‚½ãƒ¼ãƒˆï¼ˆå€¤ã®åˆ—ã§ï¼‰
                            if len(result_df) > 0:
                                result_df_sorted = result_df.sort_values(by=result_df.columns[1], ascending=False)
                            else:
                                result_df_sorted = result_df
                            fig = px.bar(result_df_sorted, x=result_df_sorted.columns[0], y=result_df_sorted.columns[1])
                            st.plotly_chart(fig, use_container_width=True)
                
                except Exception as e:
                    st.error(f"SQLã‚¨ãƒ©ãƒ¼: {e}")
            
            except Exception as e:
                st.error(f"AIç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        else:
            st.warning("OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

else:
    # ãƒ‡ãƒ¼ã‚¿æœªãƒ­ãƒ¼ãƒ‰æ™‚ã®æ¡ˆå†…
    st.info("ğŸ‘ˆ å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„")
    
    with st.expander("ä½¿ã„æ–¹", expanded=True):
        st.markdown("""
### ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

1. **ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’é¸æŠ**: ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰åˆ©ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’é¸æŠ
2. **æ¥ç¶šè¨­å®š**: å¿…è¦ãªèªè¨¼æƒ…å ±ã‚’å…¥åŠ›ã—ã¦æ¥ç¶š
3. **ãƒ‡ãƒ¼ã‚¿å–å¾—**: ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
4. **è‡ªç„¶è¨€èªã§åˆ†æ**: è³ªå•ã‚’å…¥åŠ›ã—ã¦åˆ†æã‚’å®Ÿè¡Œ

### ğŸ“Š å¯¾å¿œãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹

- **ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«**: CSV, Parquet
- **BigQuery**: Google Cloud BigQuery
- **Snowflake**: Programmatic Access Tokenèªè¨¼
- **Databricks**: Personal Access Tokenèªè¨¼
- **Google Sheets**: ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼

### ğŸ’¡ è³ªå•ä¾‹

- ã€Œæœˆåˆ¥ã®å£²ä¸Šæ¨ç§»ã‚’è¦‹ã›ã¦ã€
- ã€Œã‚«ãƒ†ã‚´ãƒªåˆ¥ã®å£²ä¸Šã‚’æ£’ã‚°ãƒ©ãƒ•ã§è¡¨ç¤ºã€
- ã€Œä¸Šä½10å•†å“ã®å£²ä¸Šå‰²åˆã‚’å††ã‚°ãƒ©ãƒ•ã§ã€
- ã€Œæ˜¨å¹´åŒæœˆæ¯”ã®æˆé•·ç‡ã‚’è¨ˆç®—ã—ã¦ã€
        """)