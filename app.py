import streamlit as st
import pandas as pd
import duckdb
import plotly.express as px
import numpy as np
import re
import os
import base64
from openai import OpenAI

st.set_page_config(page_title="Vizzye", layout="wide")
st.title("ğŸ§ Vizzy")

# ãƒ­ã‚´ç”»åƒè¡¨ç¤º
def load_image(image_path):
    with open(image_path, "rb") as img_file:
        return base64.b64encode(img_file.read()).decode()

image_path = "vizzy_logo.png"
if os.path.exists(image_path):
    image_base64 = load_image(image_path)
    st.markdown(
        f"""<div style="text-align: center;">
        <img src="data:image/png;base64,{image_base64}" alt="image" style="width: 100%;"/>
        </div>""",
        unsafe_allow_html=True
    )

# èª¬æ˜
with st.expander("Vizzyã¨ã¯â”", expanded=False):
    st.markdown("""
**Vizzy** ã¯ã€è‡ªç„¶è¨€èªã§ãƒ‡ãƒ¼ã‚¿ã«è³ªå•ã§ãã‚‹ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ç”Ÿæˆã‚¢ãƒ—ãƒªã§ã™ã€‚  
CSV / Parquet / BigQuery / Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚
""")

# ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹é¸æŠ
source = st.selectbox("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’é¸æŠ", ["ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«", "BigQuery", "Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ"])

df = None

# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«
if source == "ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«":
    uploaded_file = st.file_uploader("ğŸ“„ CSVã¾ãŸã¯Parquetãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv", "parquet"])
    if uploaded_file:
        df = pd.read_csv(uploaded_file) if uploaded_file.name.endswith(".csv") else pd.read_parquet(uploaded_file)

# BigQuery
elif source == "BigQuery":
    sa_file = st.file_uploader("ğŸ” BigQueryã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆJSONã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="json", key="bq")
    if sa_file:
        with open("temp_bq.json", "wb") as f:
            f.write(sa_file.getbuffer())
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "temp_bq.json"

        from google.cloud import bigquery
        try:
            client = bigquery.Client()
            datasets = list(client.list_datasets())
            dataset_names = [d.dataset_id for d in datasets]
            selected_dataset = st.selectbox("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ", dataset_names)
            if selected_dataset:
                tables = list(client.list_tables(selected_dataset))
                table_names = [t.table_id for t in tables]
                selected_table = st.selectbox("ãƒ†ãƒ¼ãƒ–ãƒ«", table_names)
                if selected_table:
                    full_table_id = f"{client.project}.{selected_dataset}.{selected_table}"
                    df = client.query(f"SELECT * FROM `{full_table_id}` LIMIT 1000").to_dataframe()
        except Exception as e:
            st.error(f"BigQueryã‚¨ãƒ©ãƒ¼: {e}")

# Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ
elif source == "Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ":
    sa_file = st.file_uploader("ğŸ” ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆJSONã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type="json", key="sheet")
    if sa_file:
        with open("temp_sheet.json", "wb") as f:
            f.write(sa_file.read())
        import gspread
        try:
            gc = gspread.service_account(filename="temp_sheet.json")
            sheet_url = st.text_input("ğŸ“„ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®URLã‚’å…¥åŠ›")
            if sheet_url:
                sh = gc.open_by_url(sheet_url)
                worksheet_names = [ws.title for ws in sh.worksheets()]
                selected_ws = st.selectbox("ğŸ§¾ ã‚·ãƒ¼ãƒˆã‚’é¸æŠ", worksheet_names)
                if selected_ws:
                    ws = sh.worksheet(selected_ws)
                    data = ws.get_all_records()
                    df = pd.DataFrame(data)
        except Exception as e:
            st.error(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")

# å…±é€šå‡¦ç†
if df is not None:
    for col in df.columns:
        if "date" in col.lower() or "time" in col.lower():
            try:
                df[col] = pd.to_datetime(df[col])
            except:
                pass

    st.success("âœ… ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    st.dataframe(df.head())

    # DuckDBç™»éŒ²
    duck_conn = duckdb.connect()
    duck_conn.register("data", df)

    # ã‚µãƒ³ãƒ—ãƒ«
    with st.expander("ğŸ’¡ ã‚µãƒ³ãƒ—ãƒ«è³ªå•ï¼ˆå„ç¨®ã‚°ãƒ©ãƒ•å¯¾å¿œï¼‰", expanded=False):
        st.markdown("""
- ã€Œã‚«ãƒ†ã‚´ãƒªã”ã¨ã®å£²ä¸Šã‚’æ£’ã‚°ãƒ©ãƒ•ã§è¡¨ç¤ºã—ã¦ã€
- ã€Œæœˆåˆ¥ã®å£²ä¸Šæ¨ç§»ã‚’æ•™ãˆã¦ã€
- ã€Œåœ°åŸŸã”ã¨ã®å£²ä¸Šå‰²åˆã‚’å††ã‚°ãƒ©ãƒ•ã§è¦‹ã›ã¦ã€
- ã€Œæ°—æ¸©ã¨å£²ä¸Šã®é–¢ä¿‚ã‚’æ•£å¸ƒå›³ã§è¦‹ã›ã¦ã€
        """)

    # OpenAI APIã‚­ãƒ¼
    openai_api_key = st.secrets.get("OPENAI_API_KEY") or st.text_input("ğŸ”‘ OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›", type="password")
    user_input = st.chat_input("è‡ªç„¶è¨€èªã§è³ªå•ã—ã¦ãã ã•ã„")

    if user_input and openai_api_key:
        with st.chat_message("user"):
            st.markdown(user_input)

        with st.chat_message("assistant"):
            with st.spinner("åˆ†æä¸­..."):
                client = OpenAI(api_key=openai_api_key)

                schema_desc = "\n".join([f"{col} ({dtype})" for col, dtype in zip(df.columns, df.dtypes)])
                prompt = f"""
ã‚ãªãŸã¯DuckDBã«å¯¾ã—ã¦SQLã‚’ç”Ÿæˆã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ†ãƒ¼ãƒ–ãƒ«åã¯ `data` ã§ã™ã€‚

DuckDBã§ã¯æ–‡å­—åˆ—ã‚’æ—¥ä»˜é–¢æ•°ã«ä½¿ã†å ´åˆã€å¿…ãš `CAST(åˆ— AS DATE)` ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
ã€Œé–¢ä¿‚ã€ã€Œç›¸é–¢ã€ã€Œé–¢é€£ã€ãªã©ã®è³ªå•ã§ã¯ã€`SELECT col1, col2 FROM data` ã®ã‚ˆã†ã«2åˆ—ã®æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€çµæœã‚’è¿”ã—ã¦ãã ã•ã„ï¼ˆæ•£å¸ƒå›³æç”»ã®ãŸã‚ï¼‰ã€‚
å‡ºåŠ›ã¯SQLæ–‡ã®ã¿ã€‚ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚„è£…é£¾ã¯ä¸è¦ã§ã™ã€‚

ã‚¹ã‚­ãƒ¼ãƒ:
{schema_desc}

è³ªå•:
{user_input}
"""
                try:
                    response = client.chat.completions.create(
                        model="gpt-3.5-turbo",
                        messages=[
                            {"role": "system", "content": "ã‚ãªãŸã¯SQLã‚’ç”Ÿæˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚"},
                            {"role": "user", "content": prompt}
                        ]
                    )

                    raw_sql = response.choices[0].message.content.strip()
                    sql = re.sub(r"```sql|```", "", raw_sql).strip()
                    st.markdown(f"ğŸ§  **ç”Ÿæˆã•ã‚ŒãŸSQL:**\n```sql\n{sql}\n```")

                    result_df = duck_conn.execute(sql).fetchdf()
                    st.dataframe(result_df)

                    if result_df.shape[1] >= 2:
                        x, y = result_df.columns[0], result_df.columns[1]

                        q = user_input.lower()
                        if any(w in q for w in ["å‰²åˆ", "æ¯”ç‡", "ã‚·ã‚§ã‚¢", "å††"]):
                            chart_type = "pie"
                        elif any(w in q for w in ["ç›¸é–¢", "é–¢ä¿‚", "é–¢é€£"]):
                            chart_type = "scatter"
                        elif any(w in q for w in ["æ™‚é–“", "æ—¥æ™‚", "æ¨ç§»", "å‚¾å‘", "æœˆ", "æ—¥", "æ™‚ç³»åˆ—"]):
                            chart_type = "line"
                        else:
                            chart_type = "bar"

                        try:
                            result_df[x] = pd.to_datetime(result_df[x])
                        except:
                            pass

                        if chart_type == "pie":
                            st.info("ğŸ“Š å††ã‚°ãƒ©ãƒ•ã§ã‚«ãƒ†ã‚´ãƒªã”ã¨ã®å‰²åˆã‚’å¯è¦–åŒ–ã—ã¦ã„ã¾ã™")
                            fig = px.pie(result_df, names=x, values=y)
                        elif chart_type == "scatter":
                            st.info("ğŸ“ˆ æ•£å¸ƒå›³ã§2ã¤ã®æ•°å€¤ã®é–¢ä¿‚æ€§ã‚’è¦–è¦šåŒ–ã—ã¦ã„ã¾ã™ã€‚")
                            result_df[x] = pd.to_numeric(result_df[x], errors='coerce')
                            result_df[y] = pd.to_numeric(result_df[y], errors='coerce')
                            fig = px.scatter(result_df, x=x, y=y)
                            if pd.api.types.is_numeric_dtype(result_df[x]) and pd.api.types.is_numeric_dtype(result_df[y]):
                                try:
                                    corr = np.corrcoef(result_df[x], result_df[y])[0, 1]
                                    st.success(f"ğŸ“Š **ç›¸é–¢ä¿‚æ•°**: `{corr:.3f}`")
                                except:
                                    st.warning("âš ï¸ ç›¸é–¢ä¿‚æ•°ã®è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                        elif chart_type == "line":
                            st.info("ğŸ“ˆ æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•ã§æ™‚ç³»åˆ—ã®æ¨ç§»ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚")
                            fig = px.line(result_df, x=x, y=y)
                        else:
                            st.info("ğŸ“Š æ£’ã‚°ãƒ©ãƒ•ã§ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®æ¯”è¼ƒã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™ã€‚")
                            fig = px.bar(result_df, x=x, y=y)

                        st.plotly_chart(fig, use_container_width=True)

                        # ğŸ” AIã«ã‚ˆã‚‹ã‚°ãƒ©ãƒ•è¦ç´„
                        summary_prompt = f"""
ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã¯ã€Œ{chart_type}ã€ã‚°ãƒ©ãƒ•ã§å¯è¦–åŒ–ã•ã‚ŒãŸã‚‚ã®ã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€Œ{user_input}ã€ã«å¯¾ã™ã‚‹çµæœã§ã™ã€‚
ã“ã®çµæœã‹ã‚‰èª­ã¿å–ã‚Œã‚‹ãƒã‚¤ãƒ³ãƒˆã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«çµè«–ã‹ã‚‰ç­”ãˆã‚‹ã‚ˆã†ã«ã€æ—¥æœ¬èªã§ç°¡æ½”ã«æ€§æ ¼ãªãƒ‡ãƒ¼ã‚¿ã‚’å…ƒã«5è¡Œãã‚‰ã„ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚

{result_df.head(20).to_csv(index=False)}
"""
                        try:
                            summary_response = client.chat.completions.create(
                                model="gpt-3.5-turbo",
                                messages=[
                                    {"role": "system", "content": "ã‚ãªãŸã¯ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ã®å°‚é–€å®¶ã§ã€ã‚°ãƒ©ãƒ•ã‹ã‚‰èª­ã¿å–ã‚Œã‚‹å†…å®¹ã‚’ã‚ã‹ã‚Šã‚„ã™ãè¦ç´„ã—ã¾ã™ã€‚"},
                                    {"role": "user", "content": summary_prompt}
                                ]
                            )
                            summary_text = summary_response.choices[0].message.content.strip()
                            st.markdown("ğŸ“ **ã‚°ãƒ©ãƒ•ã®è¦ç´„:**")
                            st.success(summary_text)

                        except Exception as e:
                            st.warning(f"è¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

                    else:
                        st.info("ğŸ“‰ ã‚°ãƒ©ãƒ•æç”»ã«ã¯2åˆ—ä»¥ä¸Šã®çµæœãŒå¿…è¦ã§ã™ã€‚")

                except Exception as e:
                    st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

